{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Rethinking 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "I first installed R with homebrew (`brew install R`) but this didn't work out well and I couldn't install the other packeges (`rstan` and `rethinking`). Only after uninstalling R with homebrew and doin a manual installation via the [R website](https://cran.r-project.org/bin/macosx/) I could follow the installation instructions provided by McElreath. \n",
    "\n",
    "A useful line of code to see whether a package is actually installed is running `\"{name-package}\" %in% rownames(installed.packages())`. If the installation of the `{name-package}` was succesfull, this code should return `TRUE`. However, it only seems to work on the command line and not in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definities\n",
    "\n",
    "- **Bayesian statistics**: stamt van een theorie geformuleerd in 1763(!) door Thomas Bayes, die ervan uitgaat dat je de waarschijnlijkheid (_probability_) of kans van een gebeurtenis kan benaderen op basis van bestaande kennis over factoren gerelateerd aan die gebeurtenis. Een voorbeeld: als kanker (een _event_) gerelateerd is aan iemands leeftijd, dan kun je leeftijd gebruiken om de kans op kanker beter te benaderen dan als je diens leeftijd niet kent. Bayesian statistics is dus een vorm van statistiek waarin de kansverdeling de mate aangeeft waarin iemand in een event gelooft (\"probability expresses the degree of believe in an event\"). Als er nieuwe data beschikbaar is, wordt de waarschijnlijkheid opnieuw uitgerekend. Omdat er voor dit (her)berekenen veel computationele kracht nodig is, werd Bayesiaanse statistiek pas populair met de opkomst van de computers.\n",
    "\n",
    "- **Bayesian inference**: het tellen en vergelijken van mogelijkheden. Vgl. Borges' [\"Garden of Forking Paths\"](https://en.wikipedia.org/wiki/The_Garden_of_Forking_Paths): om goed te kunnen deduceren wat er echt gebeurde, zou je alles wat had kunnen gebeuren moeten overwegen. \n",
    "\n",
    "- **Bayesiaanse data analyse**: een logische procedure om informatie te verwerken. Onderzoeksvraag >> statistisch model >> testen met logica >> _probability distributions_. Met andere woorden: als we uitgaan van onze aannamens, kunnen we uitrekenen op hoeveel manieren iets gebeurd. Het is als de \"Garden of Forking Data\" waarin we verschillende mogelijke reeksen van gebeurtenissen laten groeien. Terwijl we erachter komen wat er gebeurd is, kunnen de reeksen ordenen (\"a quantitative ranking\") en sommigen snoeien. Uiteindelijk houden we één reeks over die logisch overeenkomt met onze kennis.\n",
    "\n",
    "- **Probability theory**: counting the ways things can happen.\n",
    "\n",
    "- **De null hypothese**: een algemene stelling og aanname dat er niets nieuws gebeurt, bijv. er zijn geen associates tussen groepen of geen relatie tussen twee gemeten fenomemen. Het is vaak de uitgangshypothese (H0). NOOT: als je de null hypothese gaat testen met een \"null hypothesis significance testing\" dan test je *niet* een daadwerkelijke onderzoekshypothese. Wat je  falsificeert is alleen de null hypothese; niet het achterliggende model.\n",
    "\n",
    "- Een **power law**: een functioneel verband tussen twee hoeveelheden, waarin een relatieve verandering in één hoeveelheid een proportionele verandering in de andere hoeveelheid teweeg brengt. Deze verandering is onafhankelijk van de oorspronkelijke grootte van de hoeveelheden → één hoeveelheid is de macht (_power_) van de ander.\n",
    "\n",
    "- Een **exponential family**: een _parametric set of probability distributions of a certain form_. [??] Iets met kansverdeling en parameters?\n",
    "\n",
    "- **Falsicatie**: hypothese H volgt uit observatie D. Als we D niet kunnen vinden, dan is H gefalsificeerd. Vgl.: alle zwanen zijn wit (H) >> in Europa zijn alleen maar witte zwanen (D). Omdat er in Australië wel zwarte zwanen zijn, kunnen we niet langer zeggen dat H waar is. De meeste hypotheses zijn echter niet zo stellig, maar eerder in de trant van \"80% van de zwanen is wit\". Hoe kun je deze stelling falsificeren? Bovendien is falsificatie altijd gebaseerd op wetenschappelijke consensus, _niet_ op logica. De argumenten waarop deze consensus is gebaseerd zijn vaak rommelig of verward.\n",
    "\n",
    "- **Frequentist analysis**: _probabilities_ worden gedefinieerd door deze in verband te brengen met hoe vaak iets voorkomt in grote data sets. Dit kan worden berekend door het herhalen van de metingen met de _imaginary resampling of data_: als een meting heel veel herhaald wordt, eindigen we met een lijst van waarden waarin een zeker patroon te ontdekken valt. Dit werkt niet altijd: soms kun je iets nog zo vaak herhalen zonder dat er iets verandert. In tegenstelling tot Bayesiaanse statistiek, waarbij een kans wordt toegewezen aan een hypothese, wordt bij de frequentistische aanpak alleen een hypothese getoetst zonder daar een kans aan te verbinden.\n",
    "\n",
    "- **sampling distribution**: de verspreiding van de metingen (vgl. met _probability distributions_).\n",
    "\n",
    "- **lineaire regressie**: bijv., op basis van de temperatuur voorspellen hoeveel ijsjes er worden verkocht en vaststellen of dit verband significant is. Met één of meerdere variabelen (bijv. de temperatuur, het besteedbaar inkomen ...).\n",
    "\n",
    "- **Overfitting**: de paradox van voorspellingen, _fitting is easy; prediction is hard_. Toekomstige data is niet hetzelfde als data uit het verleden, en elk model dat hier geen rekening mee houdt (hoe complex het model ook moge zijn) zal daarom slechtere voorspellingen doen. Kan worden gespot door _cross validation_ en _information criteria_ en worden tegengegaan door _partial pooling_.\n",
    "\n",
    "- **partial pooling**: voegt informatie uit verschillende data units samen om voor alle units een betere schatting te kunnen berekenen. Simpel gezegd gaat deze techniek ervan uit dat er tussen de data units variatie bestaat. \n",
    "\n",
    "- **multilevel modeling**: de hype in Bayesiaan statistiek. Door multilevel models toe te passen kun je rekening houden met veel verschillende vormen van variatie. Voorbeeld: het voorspellen van verkiezingsuitslagen, waarbij meerdere modellen meespelen (polls, eerdere uitslagen, deelresultaten, uitslagen van verwante districten, etc). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 1\n",
    "\n",
    "### Belangrijke uitgangspunten\n",
    "\n",
    "1. Een hypothese ≠ model: het model volgt vanuit een hypothese. Als je een model falsificeert, is dat niet hetzelfde als een hypothese falsificeren.\n",
    "\n",
    "2. Er is onderscheid tussen een _process model_ en een _statistical model_. Simpel gezegd volgt een _process model_ uit een hypothese en test je een _process model_ met data door middel van een _statistical model_:  hypothese >> process model >> statistical model.\n",
    "\n",
    "3. De relatie tussen model en hypothese niet 1-op-1: één hypothese is niet verbonden aan één uniek model; andersom is één model niet per sé verbonden aan één unieke hypothese. \n",
    "\n",
    "4. Hypotheses gebaseerd op observaties zijn moeilijk te staven gezien de complexe context waarin observaties gemaakt worden (o.a. _false positives_ of _false negatives_).\n",
    "\n",
    "5. Metingen kunnen misgaan; dit is regel eerder dan de uitzondering.\n",
    "\n",
    "6. _Overfitting_ kan worden gesignaleerd door _cross validation_ en _information criteria_, en worden tegengegaan door _partial pooling_.\n",
    "\n",
    "7. Het is erg lastig om statistisch te deduceren, om twee redenen: \n",
    "    (1) Verschillende _process models_ zijn verbonden met dezelfde statistische model. Een oplossing hiervoor is om te kijken naar andere aspecten van de _process models_. Vb: twee _process models_ voorspellen ongeveer hetzelfde wat betreft _frequency distribution_, maar ze voorspellen iets heel anders als het gaat om de de verspreiding van veranderingen over tijd. \n",
    "    (2) Een statistisch model alleen is niet voldoende om causaliteit af te leiden, want het maakt geen onderscheid tussen oorzaak en gevolg: het detecteert slechts een verband tussen oorzaak en gevolg. Vb: een statistich model detecteert een verband tussen de wind en de bewegende takken, maar niet of de wind te takken doet bewegen of dat de takken de wind doen blazen. \n",
    "\n",
    "### Modellen vergelijken\n",
    "\n",
    "In de Bayesiaanse statistiek bestaan meerdere modellen. Hoe weet je welk model geschikt is, met andere woorden, welk model de beste voorspellingen doet (_predictive accuracy_)? Hiervoor kun je gebruik maken van *cross validation* of *information criteria*. \n",
    "\n",
    "Nadat je met deze twee methodes _overfitting_ hebt opgespeurd, kun je dit tegengaan door _partial pooling_ (→ multilevel modeling) en _causal identification_ (een model waarin wordt aangegeven welke variabelen elkaar beinvloeden). De causale modelen komen vaak in de vorm van DAGs waarin een causale hypothese is uitgetekend. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Een model is altijd een simplificatie van de werkelijkheid. \n",
    "\n",
    "### Counting \n",
    "Je start met een gegeven en een vraagstuk hierover, bijv: \"gegeven deze zak met vier blauwe en witte knikkers (>je kennis) en je hebt drie keer blind een knikker getrokken (> je data/observatie). Hoeveel blauwe en hoeveel witte knikkers zitten er in de zak? (> je vraag)\" \n",
    "\n",
    "Op basis van de data en je kennis weet je dat er vijf mogelijkheden zijn (_conjectures_ of **parameter value**). Welke van de vijf mogelijkheden is het meest plausibel? Dit kun je berekenen door te tellen.\n",
    "\n",
    "### Combining other information\n",
    "\n",
    "Je krijgt extra informatie, dus deze wil je meenemen in je berekeningen van de plausibiliteit. Je oorspronkelijke berekeningen zijn **prior**. Deze vermenigvuldig je met de nieuwe bevindingen. Deze nieuwe bevindingen zijn **posterior**. In sommige gevallen is de data van hetzelfde type (knikkers _all the way_); in andere gevallen is een ander type data. \n",
    "\n",
    "Welke aanname moet je gebruiken als je geen andere informatie over de conjectures hebt? **Principle of indifference**\n",
    "\n",
    "### From counts to probability\n",
    "Hoe groter je dataset, hoe moeilijker het wordt om alle mogelijkheden te tellen. Daarom zul je al snel overstappen op het wiskundig uitrekenen van waarschijnlijkheid (_probability_).  \n",
    "Voorbeeld: `For [xooo], p = 1/4 = 0.25`, waarbij *p* staat voor de hoeveelheid blauwe knikkers in een reeks van vier. `Dnew = xox`, waarbij _Dnew_ staat voor een nieuwe observatie. Dat kun je wiskundig uitdrukken als: `plausibility of p after Dnew ∝ ways p can produce Dnew × prior plausibility of p`, waarbij ∝ betekent \"evenredig aan\". In mensentaal zeg je dus: voor iedere waarde van _p_ (_p value_), is de kans dat evenredig aan het aantal manieren waarop het door de \"Garden of Forking Data\" kan gaan. Tot slot wordt de kansberekening gestandardiseerd door te zorgen dat de som van alle mogelijkheden 1 is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>0</li>\n",
       "\t<li>0.15</li>\n",
       "\t<li>0.4</li>\n",
       "\t<li>0.45</li>\n",
       "\t<li>0</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 0\n",
       "\\item 0.15\n",
       "\\item 0.4\n",
       "\\item 0.45\n",
       "\\item 0\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 0\n",
       "2. 0.15\n",
       "3. 0.4\n",
       "4. 0.45\n",
       "5. 0\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 0.00 0.15 0.40 0.45 0.00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ways <- c(0,3,8,9,0)\n",
    "ways/sum(ways)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOOT: het moge dan \"makkelijk\" zijn om bovenstaande berekeningen in R uit te voeren (zie \"code 2.1\" op p. 27), maar de \"ways to produce data\" zijn nog altijd handmatig geteld op basis van de graph. Dit moet toch anders kunnen?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
